model:
  model_id: meta-llama/Llama-3.2-3B-Instruct
  device: cuda
  dtype: bfloat16

experiment:
  max_tokens: 512
  temperature: 0.7
  n_samples: 128

benchmark:
  type: gsm8k_jsonl
  params:
    path: ../datasets/GSM8K/test.jsonl # relative to yml always (will be resolved by cli)
    limit:             

verifier:
  type: boxed_number
  params:
    tol: 0.00001
