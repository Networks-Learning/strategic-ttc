model:
  model_id: meta-llama/Llama-3.2-3B-Instruct
  device: cuda
  dtype: bfloat16

experiment:
  max_tokens: 1024
  temperature: 1.2
  n_samples: 300

benchmark:
  type: mgsm_jsonl
  params:
    path: ../datasets/GSM8K/en.jsonl # relative to yml always (will be resolved by cli)
    limit:             

verifier:
  type: boxed_number
  params:
    tol: 0.00001
