model:
  model_id: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  device: cuda
  dtype: bfloat16

experiment:
  max_tokens: 512
  temperature: 0.6
  n_samples: 128
  output_path: ../runs/GSM8K/R1-D-Llama-8B--temp-0.6--samples-128--max-512.jsonl

benchmark:
  type: gsm8k_jsonl
  params:
    path: ../datasets/GSM8K/test.jsonl
    limit:             

verifier:
  type: boxed_number
  params:
    tol: 0.00001

