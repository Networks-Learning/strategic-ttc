model:
  model_id: meta-llama/Llama-3.1-8B-Instruct
  device: cuda
  dtype: bfloat16

experiment:
  max_tokens: 512
  temperature: 0.6
  n_samples: 128
  output_path: ../final_runs/AIME/Llama-3.1-8B--temp-0.6--samples-128--max-512.jsonl

  system_prompt: Please reason step by step, and put your final answer within \boxed{}.
  reasoning: false

benchmark:
  type: gsm8k_jsonl
  params:
    path: ../datasets/AIME/test.jsonl

verifier:
  type: boxed_number
  params:
    tol: 0.00001

